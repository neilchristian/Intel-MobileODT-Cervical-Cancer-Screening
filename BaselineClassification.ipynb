{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nfrom skimage.io import imread, imshow\nimport cv2\npy.init_notebook_mode(connected=True)\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input/train\"]).decode(\"utf8\"))",
      "execution_count": 27,
      "outputs": [
        {
          "data": {
            "text/html": "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>",
            "text/vnd.plotly.v1+html": "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Type_1\nType_2\nType_3\n\n"
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from glob import glob\nbasepath = '../input/train/'\n\nall_cervix_images = []\n\nfor path in sorted(glob(basepath + \"*\")):\n    cervix_type = path.split(\"/\")[-1]\n    cervix_images = sorted(glob(basepath + cervix_type + \"/*\"))\n    all_cervix_images = all_cervix_images + cervix_images\n\nall_cervix_images = pd.DataFrame({'imagepath': all_cervix_images})\nall_cervix_images['filetype'] = all_cervix_images.apply(lambda row: row.imagepath.split(\".\")[-1], axis=1)\nall_cervix_images['type'] = all_cervix_images.apply(lambda row: row.imagepath.split(\"/\")[-2], axis=1)",
      "execution_count": 4,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from collections import defaultdict\n\nimages = defaultdict(list)\n\nfor t in all_cervix_images['type'].unique():\n    sample_counter = 0\n    for _, row in all_cervix_images[all_cervix_images['type'] == t].iterrows():\n        #print('reading image {}'.format(row.imagepath))\n        try:\n            img = imread(row.imagepath)\n            sample_counter +=1\n            images[t].append(img)\n        except:\n            print('image read failed for {}'.format(row.imagepath))\n        if sample_counter > 35:\n            break\n           ",
      "execution_count": 5,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "dfs = []\nfor t in all_cervix_images['type'].unique():\n    t_ = pd.DataFrame(\n        {\n            'nrows': list(map(lambda i: i.shape[0], images[t])),\n            'ncols': list(map(lambda i: i.shape[1], images[t])),\n            'nchans': list(map(lambda i: i.shape[2], images[t])),\n            'type': t\n        }\n    )\n    dfs.append(t_)\n\nshapes_df = pd.concat(dfs, axis=0)\nshapes_df_grouped = shapes_df.groupby(by=['nchans', 'ncols', 'nrows', 'type']).size().reset_index().sort_values(['type', 0], ascending=False)",
      "execution_count": 6,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def transform_image(img, rescaled_dim, to_gray=False):\n    resized = cv2.resize(img, (rescaled_dim, rescaled_dim), cv2.INTER_LINEAR)\n\n    if to_gray:\n        resized = cv2.cvtColor(resized, cv2.COLOR_RGB2GRAY).astype('float')\n    else:\n        resized = resized.astype('float')\n\n    normalized = cv2.normalize(resized, None, 0.0, 1.0, cv2.NORM_MINMAX)\n    timg = normalized.reshape(1, np.prod(normalized.shape))\n\n    return timg/np.linalg.norm(timg)\n\nrescaled_dim = 100\n\nall_images = []\nall_image_types = []\n\nfor t in all_cervix_images['type'].unique():\n    all_images = all_images + images[t]\n    all_image_types = all_image_types + len(images[t])*[t]\n\n# - normalize each uint8 image to the value interval [0, 1] as float image\n# - rgb to gray\n# - downsample image to rescaled_dim X rescaled_dim\n# - L2 norm of each sample = 1\ngray_all_images_as_vecs = [transform_image(img, rescaled_dim) for img in all_images]\n\ngray_imgs_mat = np.array(gray_all_images_as_vecs).squeeze()\nall_image_types = np.array(all_image_types)\ngray_imgs_mat.shape, all_image_types.shape",
      "execution_count": 7,
      "outputs": [
        {
          "data": {
            "text/plain": "((108, 30000), (108,))"
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "gray_imgs_mat.shape",
      "execution_count": 8,
      "outputs": [
        {
          "data": {
            "text/plain": "(108, 30000)"
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "----------",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import Normalizer\ny = LabelEncoder().fit_transform(all_image_types).reshape(-1)\nX = gray_imgs_mat # no need for normalizing, we already did this earlier Normalizer().fit_transform(gray_imgs_mat)\nX.shape, y.shape",
      "execution_count": 10,
      "outputs": [
        {
          "data": {
            "text/plain": "((108, 30000), (108,))"
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV, train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\nX_train.shape, X_test.shape, y_train.shape, y_test.shape",
      "execution_count": 11,
      "outputs": [
        {
          "data": {
            "text/plain": "((72, 30000), (36, 30000), (72,), (36,))"
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "y_train, y_test",
      "execution_count": 12,
      "outputs": [
        {
          "data": {
            "text/plain": "(array([0, 1, 0, 1, 2, 1, 0, 0, 2, 0, 1, 0, 1, 1, 2, 0, 0, 2, 2, 0, 1, 1, 0,\n        0, 0, 0, 1, 0, 2, 0, 1, 2, 2, 1, 1, 2, 1, 2, 1, 2, 2, 1, 1, 1, 2, 1,\n        2, 0, 2, 1, 1, 2, 1, 0, 2, 0, 1, 0, 0, 0, 2, 2, 2, 2, 2, 0, 1, 1, 0,\n        2, 1, 2]),\n array([2, 0, 0, 2, 1, 1, 0, 1, 2, 0, 2, 2, 0, 2, 0, 1, 1, 2, 2, 1, 0, 1, 1,\n        0, 0, 0, 1, 2, 0, 1, 2, 2, 0, 0, 1, 2]))"
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "\nLogistic Regression\n===================\n",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "clf = LogisticRegression()\ngrid = {\n    'C': [1e-9, 1e-6, 1e-3, 1e0],\n    'penalty': ['l1', 'l2']\n}\ncv = GridSearchCV(clf, grid, scoring='neg_log_loss', n_jobs=-1, verbose=1)\ncv.fit(X_train, y_train)",
      "execution_count": 13,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "[Parallel(n_jobs=-1)]: Done  18 out of  24 | elapsed:   13.7s remaining:    4.6s\n[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   15.0s finished\n"
        },
        {
          "data": {
            "text/plain": "GridSearchCV(cv=None, error_score='raise',\n       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False),\n       fit_params={}, iid=True, n_jobs=-1,\n       param_grid={'C': [1e-09, 1e-06, 0.001, 1.0], 'penalty': ['l1', 'l2']},\n       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n       scoring='neg_log_loss', verbose=1)"
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "for i in range(1, len(cv.cv_results_['params'])+1):\n    rank = cv.cv_results_['rank_test_score'][i-1]\n    s = cv.cv_results_['mean_test_score'][i-1]\n    sd = cv.cv_results_['std_test_score'][i-1]\n    params = cv.cv_results_['params'][i-1]\n    print(\"{0}. Mean validation neg log loss: {1:.6f} (std: {2:.6f}) - {3}\".format(\n        rank,\n        s,\n        sd,\n        params\n    ))",
      "execution_count": 14,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "5. Mean validation neg log loss: -1.098612 (std: 0.000000) - {'C': 1e-09, 'penalty': 'l1'}\n4. Mean validation neg log loss: -1.098612 (std: 0.000000) - {'C': 1e-09, 'penalty': 'l2'}\n5. Mean validation neg log loss: -1.098612 (std: 0.000000) - {'C': 1e-06, 'penalty': 'l1'}\n3. Mean validation neg log loss: -1.098612 (std: 0.000000) - {'C': 1e-06, 'penalty': 'l2'}\n5. Mean validation neg log loss: -1.098612 (std: 0.000000) - {'C': 0.001, 'penalty': 'l1'}\n2. Mean validation neg log loss: -1.098585 (std: 0.000032) - {'C': 0.001, 'penalty': 'l2'}\n8. Mean validation neg log loss: -1.098710 (std: 0.000749) - {'C': 1.0, 'penalty': 'l1'}\n1. Mean validation neg log loss: -1.091674 (std: 0.028704) - {'C': 1.0, 'penalty': 'l2'}\n"
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**Neural Network**\n------------------",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.neural_network import MLPClassifier\ncv = MLPClassifier()\n\n\ncv = GridSearchCV(clf, param_grid={\n    'activation': [\"logistic\", 'relu', 'tanh']} , scoring = 'neg_log_loss',verbose = 1)\ncv.fit(X_train, y_train)\n\nfor i in range(1, len(cv.cv_results_['params'])+1):\n    rank = cv.cv_results_['rank_test_score'][i-1]\n    s = cv.cv_results_['mean_test_score'][i-1]\n    sd = cv.cv_results_['std_test_score'][i-1]\n    params = cv.cv_results_['params'][i-1]\n    print(\"{0}. Mean validation neg log loss: {1:.6f} (std: {2:.6f}) - {3}\".format(\n        rank,\n        s,\n        sd,\n        params\n    ))",
      "execution_count": 23,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning:\n\nStochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning:\n\nStochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning:\n\nStochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning:\n\nStochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning:\n\nStochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning:\n\nStochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n\n/opt/conda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning:\n\nStochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n\n[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  8.6min finished\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "1. Mean validation neg log loss: -1.961057 (std: 0.506868) - {'activation': 'logistic'}\n2. Mean validation neg log loss: -2.524468 (std: 0.748185) - {'activation': 'relu'}\n3. Mean validation neg log loss: -2.739268 (std: 0.762039) - {'activation': 'tanh'}\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning:\n\nStochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n\n"
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Random Forest\n=======",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.ensemble import RandomForestClassifier\n\nclf_RF = RandomForestClassifier()\n\nparam_grid = {\n              \"bootstrap\": [True, False],\n              \"criterion\": [\"gini\", \"entropy\"]}\n\n# run grid search\ncv = GridSearchCV(clf_RF, param_grid=param_grid, cv = 10, scoring = 'neg_log_loss')\ncv.fit(X_train, y_train)\n\nfor i in range(1, len(cv.cv_results_['params'])+1):\n    rank = cv.cv_results_['rank_test_score'][i-1]\n    s = cv.cv_results_['mean_test_score'][i-1]\n    sd = cv.cv_results_['std_test_score'][i-1]\n    params = cv.cv_results_['params'][i-1]\n    print(\"{0}. Mean validation neg log loss: {1:.6f} (std: {2:.6f}) - {3}\".format(\n        rank,\n        s,\n        sd,\n        params\n    ))",
      "execution_count": 24,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "1. Mean validation neg log loss: -2.059936 (std: 1.733276) - {'bootstrap': True, 'criterion': 'gini'}\n4. Mean validation neg log loss: -3.862147 (std: 3.467242) - {'bootstrap': True, 'criterion': 'entropy'}\n3. Mean validation neg log loss: -3.855064 (std: 3.761134) - {'bootstrap': False, 'criterion': 'gini'}\n2. Mean validation neg log loss: -2.478046 (std: 2.043563) - {'bootstrap': False, 'criterion': 'entropy'}\n"
        }
      ],
      "metadata": {}
    }
  ]
}